{"docstore/metadata": {"54305d07-f21a-431c-b3cb-0bbb5913ae9c": {"doc_hash": "ceb1e6d893c89369f8eb6e4056f120526e499a77906761855607f0b8f34e49c0"}, "56134cd0-2561-4103-a839-3cb9dcdbaa8f": {"doc_hash": "1ac22c2a54da98e0442129f1c0611bebf8b1f21b17053183c3fc62448abe7eb1"}, "0501efcf-22f9-47ba-ad6d-273bf7552624": {"doc_hash": "531e66a039269ee6cc0b9171b9983e49d4f345eab005142b2da3a8af64bbdb38"}, "2a7077d5-354e-4f70-9a02-e5521fd6fed5": {"doc_hash": "77922925fc1fd352098d400f8fc4603f6e3d5779749609f4f1eb317d1812c7d9"}, "b11995ac-3a2d-4810-a84a-f638ea91b128": {"doc_hash": "3fd604e58cff58ea45fe33622f61c4c5f9a8ea02c6c2040c9cd0ed1cbe0c0a61"}, "b16baa62-b498-4c18-8dfe-99190a6fa9c3": {"doc_hash": "67a4976077d97ea6287129f07f9b3d81e95338acd96bd6749a4c066bd4ac876d", "ref_doc_id": "54305d07-f21a-431c-b3cb-0bbb5913ae9c"}, "219d93d1-0513-42db-9492-7ad86cfc8566": {"doc_hash": "26671f29ac72b55ae287b0627bd57737bc07e453724d80aeee855dcbb2603fb0", "ref_doc_id": "54305d07-f21a-431c-b3cb-0bbb5913ae9c"}, "e072b0d7-d9ae-4428-9655-4a50a88853c9": {"doc_hash": "1ac22c2a54da98e0442129f1c0611bebf8b1f21b17053183c3fc62448abe7eb1", "ref_doc_id": "56134cd0-2561-4103-a839-3cb9dcdbaa8f"}, "3a215028-60f9-4b06-8f2b-072931ffcffd": {"doc_hash": "531e66a039269ee6cc0b9171b9983e49d4f345eab005142b2da3a8af64bbdb38", "ref_doc_id": "0501efcf-22f9-47ba-ad6d-273bf7552624"}, "a5b52163-66da-416e-bccd-e2f8040b4e52": {"doc_hash": "7f158fdbb282cb6a569669ab7aba45d83b1d95d81236cdfa38f55376120f31a5", "ref_doc_id": "2a7077d5-354e-4f70-9a02-e5521fd6fed5"}, "1b079548-f73a-4c38-baf3-870e87a4abcd": {"doc_hash": "5e90e8ecd94e55203c526e9cb4a26b62e0ca2c5173bf6f38f8d982530436cb0d", "ref_doc_id": "b11995ac-3a2d-4810-a84a-f638ea91b128"}}, "docstore/data": {"b16baa62-b498-4c18-8dfe-99190a6fa9c3": {"__data__": {"id_": "b16baa62-b498-4c18-8dfe-99190a6fa9c3", "embedding": null, "metadata": {"page_label": "1", "file_name": "2023_GPT4All_Technical_Report.pdf", "file_path": "pdfs\\2023_GPT4All_Technical_Report.pdf", "file_type": "application/pdf", "file_size": 3651423, "creation_date": "2024-02-06", "last_modified_date": "2024-02-05", "last_accessed_date": "2024-02-06"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "54305d07-f21a-431c-b3cb-0bbb5913ae9c", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2023_GPT4All_Technical_Report.pdf", "file_path": "pdfs\\2023_GPT4All_Technical_Report.pdf", "file_type": "application/pdf", "file_size": 3651423, "creation_date": "2024-02-06", "last_modified_date": "2024-02-05", "last_accessed_date": "2024-02-06"}, "hash": "ceb1e6d893c89369f8eb6e4056f120526e499a77906761855607f0b8f34e49c0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "219d93d1-0513-42db-9492-7ad86cfc8566", "node_type": "1", "metadata": {}, "hash": "ab827a6df77ca4edd06a07188847e7f45bd0811f617ee6f630dd8c60d68f2012", "class_name": "RelatedNodeInfo"}}, "text": "GPT4All: Training an Assistant-style Chatbot with Large Scale Data\nDistillation from GPT-3.5-Turbo\nYuvanesh Anand\nyuvanesh@nomic.aiZach Nussbaum\nzanussbaum@gmail.com\nBrandon Duderstadt\nbrandon@nomic.aiBenjamin Schmidt\nben@nomic.aiAndriy Mulyar\nandriy@nomic.ai\nAbstract\nThis preliminary technical report describes the\ndevelopment of GPT4All, a chatbot trained\nover a massive curated corpus of assistant in-\nteractions including word problems, story de-\nscriptions, multi-turn dialogue, and code. We\nopenly release the collected data, data cura-\ntion procedure, training code, and final model\nweights to promote open research and repro-\nducibility. Additionally, we release quantized\n4-bit versions of the model allowing virtually\nanyone to run the model on CPU.\n1 Data Collection and Curation\nWe collected roughly one million prompt-\nresponse pairs using the GPT-3.5-Turbo OpenAI\nAPI between March 20, 2023 and March 26th,\n2023. To do this, we first gathered a diverse sam-\nple of questions/prompts by leveraging three pub-\nlicly available datasets:\n\u2022 The unified chip2 subset of LAION OIG.\n\u2022 Coding questions with a random sub-sample\nof Stackoverflow Questions\n\u2022 Instruction-tuning with a sub-sample of Big-\nscience/P3\nWe chose to dedicate substantial attention to data\npreparation and curation based on commentary in\nthe Stanford Alpaca project (Taori et al., 2023).\nUpon collection of the initial dataset of prompt-\ngeneration pairs, we loaded data into Atlas for data\ncuration and cleaning. With Atlas, we removed all\nexamples where GPT-3.5-Turbo failed to respond\nto prompts and produced malformed output. This\nreduced our total number of examples to 806,199\nhigh-quality prompt-generation pairs. Next, we\ndecided to remove the entire Bigscience/P3 sub-\nset from the final training dataset due to its very\nFigure 1: TSNE visualization of the candidate training\ndata (Red: Stackoverflow, Orange: chip2, Blue: P3).\nThe large blue balls (e.g. indicated by the red arrow)\nare highly homogeneous prompt-response pairs.\nlow output diversity; P3 contains many homoge-\nneous prompts which produce short and homoge-\nneous responses from GPT-3.5-Turbo. This exclu-\nsion produces a final subset containing 437,605\nprompt-generation pairs, which is visualized in\nFigure 2.", "start_char_idx": 0, "end_char_idx": 2264, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "219d93d1-0513-42db-9492-7ad86cfc8566": {"__data__": {"id_": "219d93d1-0513-42db-9492-7ad86cfc8566", "embedding": null, "metadata": {"page_label": "1", "file_name": "2023_GPT4All_Technical_Report.pdf", "file_path": "pdfs\\2023_GPT4All_Technical_Report.pdf", "file_type": "application/pdf", "file_size": 3651423, "creation_date": "2024-02-06", "last_modified_date": "2024-02-05", "last_accessed_date": "2024-02-06"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "54305d07-f21a-431c-b3cb-0bbb5913ae9c", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2023_GPT4All_Technical_Report.pdf", "file_path": "pdfs\\2023_GPT4All_Technical_Report.pdf", "file_type": "application/pdf", "file_size": 3651423, "creation_date": "2024-02-06", "last_modified_date": "2024-02-05", "last_accessed_date": "2024-02-06"}, "hash": "ceb1e6d893c89369f8eb6e4056f120526e499a77906761855607f0b8f34e49c0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b16baa62-b498-4c18-8dfe-99190a6fa9c3", "node_type": "1", "metadata": {"page_label": "1", "file_name": "2023_GPT4All_Technical_Report.pdf", "file_path": "pdfs\\2023_GPT4All_Technical_Report.pdf", "file_type": "application/pdf", "file_size": 3651423, "creation_date": "2024-02-06", "last_modified_date": "2024-02-05", "last_accessed_date": "2024-02-06"}, "hash": "67a4976077d97ea6287129f07f9b3d81e95338acd96bd6749a4c066bd4ac876d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e072b0d7-d9ae-4428-9655-4a50a88853c9", "node_type": "1", "metadata": {}, "hash": "3a69e921899955d9aa8985c5cc2311dd271c34e3fde65f1340f35667e329180e", "class_name": "RelatedNodeInfo"}}, "text": "With Atlas, we removed all\nexamples where GPT-3.5-Turbo failed to respond\nto prompts and produced malformed output. This\nreduced our total number of examples to 806,199\nhigh-quality prompt-generation pairs. Next, we\ndecided to remove the entire Bigscience/P3 sub-\nset from the final training dataset due to its very\nFigure 1: TSNE visualization of the candidate training\ndata (Red: Stackoverflow, Orange: chip2, Blue: P3).\nThe large blue balls (e.g. indicated by the red arrow)\nare highly homogeneous prompt-response pairs.\nlow output diversity; P3 contains many homoge-\nneous prompts which produce short and homoge-\nneous responses from GPT-3.5-Turbo. This exclu-\nsion produces a final subset containing 437,605\nprompt-generation pairs, which is visualized in\nFigure 2. You can interactively explore the dataset\nat each stage of cleaning at the following links:\n\u2022 Cleaned with P3\n\u2022 Cleaned without P3 (Final Training Dataset)\n2 Model Training\nWe train several models finetuned from an in-\nstance of LLaMA 7B (Touvron et al., 2023).\nThe model associated with our initial public re-\nlease is trained with LoRA (Hu et al., 2021)\non the 437,605 post-processed examples for four\nepochs. Detailed model hyper-parameters and\ntraining code can be found in the associated repos-\nitory and model training log.", "start_char_idx": 1494, "end_char_idx": 2794, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e072b0d7-d9ae-4428-9655-4a50a88853c9": {"__data__": {"id_": "e072b0d7-d9ae-4428-9655-4a50a88853c9", "embedding": null, "metadata": {"page_label": "2", "file_name": "2023_GPT4All_Technical_Report.pdf", "file_path": "pdfs\\2023_GPT4All_Technical_Report.pdf", "file_type": "application/pdf", "file_size": 3651423, "creation_date": "2024-02-06", "last_modified_date": "2024-02-05", "last_accessed_date": "2024-02-06"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "56134cd0-2561-4103-a839-3cb9dcdbaa8f", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2023_GPT4All_Technical_Report.pdf", "file_path": "pdfs\\2023_GPT4All_Technical_Report.pdf", "file_type": "application/pdf", "file_size": 3651423, "creation_date": "2024-02-06", "last_modified_date": "2024-02-05", "last_accessed_date": "2024-02-06"}, "hash": "1ac22c2a54da98e0442129f1c0611bebf8b1f21b17053183c3fc62448abe7eb1", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "219d93d1-0513-42db-9492-7ad86cfc8566", "node_type": "1", "metadata": {"page_label": "1", "file_name": "2023_GPT4All_Technical_Report.pdf", "file_path": "pdfs\\2023_GPT4All_Technical_Report.pdf", "file_type": "application/pdf", "file_size": 3651423, "creation_date": "2024-02-06", "last_modified_date": "2024-02-05", "last_accessed_date": "2024-02-06"}, "hash": "26671f29ac72b55ae287b0627bd57737bc07e453724d80aeee855dcbb2603fb0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3a215028-60f9-4b06-8f2b-072931ffcffd", "node_type": "1", "metadata": {}, "hash": "2a3810c54b8d172f4287a9fdf9ee5ed4b068123cee9ed781aa212d691b228e70", "class_name": "RelatedNodeInfo"}}, "text": "(a) TSNE visualization of the final training data, ten-colored\nby extracted topic.\n(b) Zoomed in view of Figure 2a. The region displayed con-\ntains generations related to personal health and wellness.\nFigure 2: The final training data was curated to ensure a diverse distribution of prompt topics and model responses.\n2.1 Reproducibility\nWe release all data (including unused P3 genera-\ntions), training code, and model weights for the\ncommunity to build upon. Please check the Git\nrepository for the most up-to-date data, training\ndetails and checkpoints.\n2.2 Costs\nWe were able to produce these models with about\nfour days work, $800 in GPU costs (rented from\nLambda Labs and Paperspace) including several\nfailed trains, and $500 in OpenAI API spend.\nOur released model, gpt4all-lora, can be trained in\nabout eight hours on a Lambda Labs DGX A100\n8x 80GB for a total cost of $100 .\n3 Evaluation\nWe perform a preliminary evaluation of our model\nusing the human evaluation data from the Self-\nInstruct paper (Wang et al., 2022). We report the\nground truth perplexity of our model against what\nis, to our knowledge, the best openly available\nalpaca-lora model, provided by user chainyo on\nhuggingface. We find that all models have very\nlarge perplexities on a small number of tasks, and\nreport perplexities clipped to a maximum of 100.\nModels finetuned on this collected dataset ex-\nhibit much lower perplexity in the Self-Instruct\nevaluation compared to Alpaca. This evaluation is\nin no way exhaustive and further evaluation work\nFigure 3: Model Perplexities. Lower is better. Our\nmodels achieve stochastically lower ground truth per-\nplexities than alpaca-lora.\nremains. We welcome the reader to run the model\nlocally on CPU (see Github for files) and get a\nqualitative sense of what it can do.\n4 Use Considerations\nThe authors release data and training details in\nhopes that it will accelerate open LLM research,\nparticularly in the domains of alignment and inter-\npretability. GPT4All model weights and data are\nintended and licensed only for research purposes\nand any commercial use is prohibited. GPT4All\nis based on LLaMA, which has a non-commercial\nlicense. The assistant data is gathered from Ope-\nnAI\u2019s GPT-3.5-Turbo, whose terms of use pro-", "start_char_idx": 0, "end_char_idx": 2250, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3a215028-60f9-4b06-8f2b-072931ffcffd": {"__data__": {"id_": "3a215028-60f9-4b06-8f2b-072931ffcffd", "embedding": null, "metadata": {"page_label": "3", "file_name": "2023_GPT4All_Technical_Report.pdf", "file_path": "pdfs\\2023_GPT4All_Technical_Report.pdf", "file_type": "application/pdf", "file_size": 3651423, "creation_date": "2024-02-06", "last_modified_date": "2024-02-05", "last_accessed_date": "2024-02-06"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0501efcf-22f9-47ba-ad6d-273bf7552624", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2023_GPT4All_Technical_Report.pdf", "file_path": "pdfs\\2023_GPT4All_Technical_Report.pdf", "file_type": "application/pdf", "file_size": 3651423, "creation_date": "2024-02-06", "last_modified_date": "2024-02-05", "last_accessed_date": "2024-02-06"}, "hash": "531e66a039269ee6cc0b9171b9983e49d4f345eab005142b2da3a8af64bbdb38", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e072b0d7-d9ae-4428-9655-4a50a88853c9", "node_type": "1", "metadata": {"page_label": "2", "file_name": "2023_GPT4All_Technical_Report.pdf", "file_path": "pdfs\\2023_GPT4All_Technical_Report.pdf", "file_type": "application/pdf", "file_size": 3651423, "creation_date": "2024-02-06", "last_modified_date": "2024-02-05", "last_accessed_date": "2024-02-06"}, "hash": "1ac22c2a54da98e0442129f1c0611bebf8b1f21b17053183c3fc62448abe7eb1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a5b52163-66da-416e-bccd-e2f8040b4e52", "node_type": "1", "metadata": {}, "hash": "a7a6285fac5ab20595032ccaca869cbfad3086256177f291fb68faadcd2a4791", "class_name": "RelatedNodeInfo"}}, "text": "hibit developing models that compete commer-\ncially with OpenAI.\nReferences\nEdward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan\nAllen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and\nWeizhu Chen. 2021. Lora: Low-rank adaptation of\nlarge language models.\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann\nDubois, Xuechen Li, Carlos Guestrin, Percy\nLiang, and Tatsunori B. Hashimoto. 2023. Stan-\nford alpaca: An instruction-following llama\nmodel. https://github.com/tatsu-lab/\nstanford_alpaca .\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timoth \u00b4ee Lacroix,\nBaptiste Rozi `ere, Naman Goyal, Eric Hambro,\nFaisal Azhar, Aurelien Rodriguez, Armand Joulin,\nEdouard Grave, and Guillaume Lample. 2023.\nLlama: Open and efficient foundation language\nmodels.\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Al-\nisa Liu, Noah A. Smith, Daniel Khashabi, and Han-\nnaneh Hajishirzi. 2022. Self-instruct: Aligning lan-\nguage model with self generated instructions.", "start_char_idx": 0, "end_char_idx": 977, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a5b52163-66da-416e-bccd-e2f8040b4e52": {"__data__": {"id_": "a5b52163-66da-416e-bccd-e2f8040b4e52", "embedding": null, "metadata": {"page_label": "1", "file_name": "fastfacts-what-is-climate-change.pdf", "file_path": "pdfs\\fastfacts-what-is-climate-change.pdf", "file_type": "application/pdf", "file_size": 389755, "creation_date": "2024-02-06", "last_modified_date": "2024-02-04", "last_accessed_date": "2024-02-06"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2a7077d5-354e-4f70-9a02-e5521fd6fed5", "node_type": "4", "metadata": {"page_label": "1", "file_name": "fastfacts-what-is-climate-change.pdf", "file_path": "pdfs\\fastfacts-what-is-climate-change.pdf", "file_type": "application/pdf", "file_size": 389755, "creation_date": "2024-02-06", "last_modified_date": "2024-02-04", "last_accessed_date": "2024-02-06"}, "hash": "77922925fc1fd352098d400f8fc4603f6e3d5779749609f4f1eb317d1812c7d9", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3a215028-60f9-4b06-8f2b-072931ffcffd", "node_type": "1", "metadata": {"page_label": "3", "file_name": "2023_GPT4All_Technical_Report.pdf", "file_path": "pdfs\\2023_GPT4All_Technical_Report.pdf", "file_type": "application/pdf", "file_size": 3651423, "creation_date": "2024-02-06", "last_modified_date": "2024-02-05", "last_accessed_date": "2024-02-06"}, "hash": "531e66a039269ee6cc0b9171b9983e49d4f345eab005142b2da3a8af64bbdb38", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1b079548-f73a-4c38-baf3-870e87a4abcd", "node_type": "1", "metadata": {}, "hash": "5e0f33a700703a8f617f5345a0fa7d1e6eb9ee4e3ec84bc834d9b5278b2d1030", "class_name": "RelatedNodeInfo"}}, "text": "What Is Climate Change?\n1. Climate change  can be a natural process where temperature, rainfall, wind and \nother elements vary over decades or more. In millions of years, our world has been \nwarmer and colder than it is now. But today we are experiencing rapid warming from \nhuman activities, primarily due to burning fossil fuels that generate greenhouse gas \nemissions.\n2. Increasing greenhouse gas emissions  from human activity act like a blanket \nwrapped around the earth, trapping the sun\u2019s heat and raising temperatures.\n3. Examples of greenhouse gas emissions that are causing climate change include \ncarbon dioxide and methane. These come from burning fossil fuels such as gasoline \nfor driving a car or coal for heating a building. Clearing land and forests can also \nrelease carbon dioxide. Landfills for garbage are another source. Energy, industry, \nagriculture and waste disposal are among the major emitters.\n4. Greenhouse gas concentrations are at their highest levels in 2 million years  and \ncontinue to rise. As a result, the earth is about 1.1\u00b0C warmer than it was in the 1800s. \nThe last decade was the warmest on record. \n5. Many people think climate change mainly means warmer temperatures. But \ntemperature rise is only the beginning of the story. Because the Earth is a system, \nwhere everything is connected, changes in one area can influence changes in all \nothers. The consequences of climate change  now include, among others, intense \ndroughts, water scarcity, severe fires, rising sea levels, flooding, melting polar ice, \ncatastrophic storms and declining biodiversity.\n6. People are experiencing climate change in diverse ways. It affects our health, \nability to grow food, housing, safety and work. Some of us are already more vulnerable \nto climate impacts, such as people living in small island developing States. Conditions \nlike sea-level rise and saltwater intrusion have advanced to the point where whole \ncommunities have had to relocate. In the future, the number of \u201cclimate refugees\u201d is \nexpected to rise.\n7. Every increase in global warming matters.  In a 2018 report, thousands of scientists \nand government reviewers agreed that limiting global temperature rise to no more \nthan 1.5\u00b0C would help us avoid the worst climate impacts and maintain a livable \nclimate. Yet the current path of carbon dioxide emissions could increase global \ntemperature by as much as 4.4\u00b0C by the end of the century . \nFAST FACTSFAST FACTS", "start_char_idx": 0, "end_char_idx": 2464, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1b079548-f73a-4c38-baf3-870e87a4abcd": {"__data__": {"id_": "1b079548-f73a-4c38-baf3-870e87a4abcd", "embedding": null, "metadata": {"page_label": "2", "file_name": "fastfacts-what-is-climate-change.pdf", "file_path": "pdfs\\fastfacts-what-is-climate-change.pdf", "file_type": "application/pdf", "file_size": 389755, "creation_date": "2024-02-06", "last_modified_date": "2024-02-04", "last_accessed_date": "2024-02-06"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b11995ac-3a2d-4810-a84a-f638ea91b128", "node_type": "4", "metadata": {"page_label": "2", "file_name": "fastfacts-what-is-climate-change.pdf", "file_path": "pdfs\\fastfacts-what-is-climate-change.pdf", "file_type": "application/pdf", "file_size": 389755, "creation_date": "2024-02-06", "last_modified_date": "2024-02-04", "last_accessed_date": "2024-02-06"}, "hash": "3fd604e58cff58ea45fe33622f61c4c5f9a8ea02c6c2040c9cd0ed1cbe0c0a61", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a5b52163-66da-416e-bccd-e2f8040b4e52", "node_type": "1", "metadata": {"page_label": "1", "file_name": "fastfacts-what-is-climate-change.pdf", "file_path": "pdfs\\fastfacts-what-is-climate-change.pdf", "file_type": "application/pdf", "file_size": 389755, "creation_date": "2024-02-06", "last_modified_date": "2024-02-04", "last_accessed_date": "2024-02-06"}, "hash": "7f158fdbb282cb6a569669ab7aba45d83b1d95d81236cdfa38f55376120f31a5", "class_name": "RelatedNodeInfo"}}, "text": "8. The emissions that cause climate change come from every part of the world and \naffect everyone, but some countries produce much more  than others. The 100 least-\nemitting countries generate 3 per cent of total emissions. The 10 largest emitters \ncontribute 68 per cent. Everyone must take climate action, but people and countries \ncreating more of the problem have a greater responsibility to act first.   \n9. Climate change is a huge challenge, but we already know many solutions. These can \ndeliver economic benefits while improving our lives and protecting the environment. We \nalso have global agreements to guide progress, such as the UN Framework Convention \non Climate Change and the Paris Agreement . Three broad categories of action are: cut \nemissions, adapt to climate impacts and finance required adjustments.\n10. Switching energy systems from fossil fuels to renewables like solar will reduce \nthe emissions driving climate change. But we have to start right now. While a growing \ncoalition of countries is committing to net zero emissions  by 2050, about half of \nemissions cuts must be in place by 2030 to keep warming below 1.5\u00b0C. Fossil fuel \nproduction must decline by roughly 6 per cent per year between 2020 and 2030. \n11. Adapting to climate consequences  protects people, homes, businesses, livelihoods, \ninfrastructure and natural ecosystems. It covers current impacts and those likely in the \nfuture. Adaptation will be required everywhere, but must be prioritized now for the most \nvulnerable people with the fewest resources to cope with climate hazards. The rate of \nreturn can be high. Early warning systems for disasters, for instance, save lives and \nproperty, and can deliver benefits up to 10 times the initial cost. \n12. We can pay the bill now, or pay dearly in the future. Climate action requires \nsignificant financial investments by governments and businesses. But climate inaction \nis vastly more expensive. One critical step is for industrialized countries to fulfil their \ncommitment to provide $100 billion a year to developing countries so they can adapt \nand move towards greener economies. \nSources: IPCC  (1), WMO  (4, 7, 10), WMO  (4), IPCC  (4, 7), UN Climate Action  (8, 10), World Bank (11).", "start_char_idx": 0, "end_char_idx": 2243, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"54305d07-f21a-431c-b3cb-0bbb5913ae9c": {"node_ids": ["b16baa62-b498-4c18-8dfe-99190a6fa9c3", "219d93d1-0513-42db-9492-7ad86cfc8566"], "metadata": {"page_label": "1", "file_name": "2023_GPT4All_Technical_Report.pdf", "file_path": "pdfs\\2023_GPT4All_Technical_Report.pdf", "file_type": "application/pdf", "file_size": 3651423, "creation_date": "2024-02-06", "last_modified_date": "2024-02-05", "last_accessed_date": "2024-02-06"}}, "56134cd0-2561-4103-a839-3cb9dcdbaa8f": {"node_ids": ["e072b0d7-d9ae-4428-9655-4a50a88853c9"], "metadata": {"page_label": "2", "file_name": "2023_GPT4All_Technical_Report.pdf", "file_path": "pdfs\\2023_GPT4All_Technical_Report.pdf", "file_type": "application/pdf", "file_size": 3651423, "creation_date": "2024-02-06", "last_modified_date": "2024-02-05", "last_accessed_date": "2024-02-06"}}, "0501efcf-22f9-47ba-ad6d-273bf7552624": {"node_ids": ["3a215028-60f9-4b06-8f2b-072931ffcffd"], "metadata": {"page_label": "3", "file_name": "2023_GPT4All_Technical_Report.pdf", "file_path": "pdfs\\2023_GPT4All_Technical_Report.pdf", "file_type": "application/pdf", "file_size": 3651423, "creation_date": "2024-02-06", "last_modified_date": "2024-02-05", "last_accessed_date": "2024-02-06"}}, "2a7077d5-354e-4f70-9a02-e5521fd6fed5": {"node_ids": ["a5b52163-66da-416e-bccd-e2f8040b4e52"], "metadata": {"page_label": "1", "file_name": "fastfacts-what-is-climate-change.pdf", "file_path": "pdfs\\fastfacts-what-is-climate-change.pdf", "file_type": "application/pdf", "file_size": 389755, "creation_date": "2024-02-06", "last_modified_date": "2024-02-04", "last_accessed_date": "2024-02-06"}}, "b11995ac-3a2d-4810-a84a-f638ea91b128": {"node_ids": ["1b079548-f73a-4c38-baf3-870e87a4abcd"], "metadata": {"page_label": "2", "file_name": "fastfacts-what-is-climate-change.pdf", "file_path": "pdfs\\fastfacts-what-is-climate-change.pdf", "file_type": "application/pdf", "file_size": 389755, "creation_date": "2024-02-06", "last_modified_date": "2024-02-04", "last_accessed_date": "2024-02-06"}}}}